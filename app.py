import argparse
import os
# Windows í™˜ê²½ì—ì„œëŠ” ì•„ë˜ ë‘ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.
# os.environ['CUDA_HOME'] = '/usr/local/cuda'
# os.environ['PATH'] = os.environ['PATH'] + ':/usr/local/cuda/bin'
from datetime import datetime

import gradio as gr
# import spaces # <--- ì´ ë¼ì¸ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì‚­ì œí•´ì•¼ í•©ë‹ˆë‹¤!
import numpy as np
import torch

# spaces ëª¨ë“ˆì´ ì—†ì„ ê²½ìš°ë¥¼ ìœ„í•œ ë”ë¯¸(dummy) í´ë˜ìŠ¤ ì •ì˜
try:
    import spaces
except ImportError:
    print("ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘: 'spaces' ëª¨ë“ˆì„ ìœ„í•œ ë”ë¯¸(dummy) ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    class DummySpaces:
        def __init__(self):
            pass
        def GPU(self, *args, **kwargs): # @spaces.GPU ë°ì½”ë ˆì´í„°ë¥¼ ìœ„í•œ ë”ë¯¸ ë©”ì„œë“œ
            def decorator(func):
                return func
            return decorator
    spaces = DummySpaces() # spaces ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë”ë¯¸ ê°ì²´ í• ë‹¹

from diffusers.image_processor import VaeImageProcessor
from huggingface_hub import snapshot_download
from PIL import Image
torch.jit.script = lambda f: f # type: ignore
from model.cloth_masker import AutoMasker, vis_mask
from model.pipeline import CatVTONPipeline
from utils import init_weight_dtype, resize_and_crop, resize_and_padding

def parse_args():
    parser = argparse.ArgumentParser(description="Simple example of a training script.")
    parser.add_argument(
        "--base_model_path", type=str, default="booksforcharlie/stable-diffusion-inpainting",
        help="The path to the base model to use for evaluation.")
    parser.add_argument(
        "--resume_path", type=str, default="zhengchong/CatVTON",
        help="The Path to the checkpoint of trained tryon model.")
    parser.add_argument(
        "--output_dir", type=str, default="resource/demo/output",
        help="The output directory where the model predictions will be written.")
    parser.add_argument("--width", type=int, default=768)
    parser.add_argument("--height", type=int, default=1024)
    parser.add_argument("--repaint", action="store_true")
    parser.add_argument("--allow_tf32", action="store_true", default=True)
    parser.add_argument("--mixed_precision", type=str, default="bf16", choices=["no", "fp16", "bf16"])
    parser.add_argument("--local_rank", type=int, default=-1, help="For distributed training: local_rank")
    args, unknown = parser.parse_known_args([])
    env_local_rank = int(os.environ.get("LOCAL_RANK", -1))
    if hasattr(args, 'local_rank') and env_local_rank != -1 and args.local_rank == -1 :
        args.local_rank = env_local_rank
    elif not hasattr(args, 'local_rank'):
        args.local_rank = env_local_rank
    return args

def image_grid(imgs, rows, cols):
    assert len(imgs) == rows * cols
    w, h = imgs[0].size
    grid = Image.new("RGB", size=(cols * w, rows * h))
    for i, img in enumerate(imgs):
        grid.paste(img, box=(i % cols * w, i // cols * h))
    return grid

args = parse_args()
# ì•„ë˜ ëª¨ë¸ ë¡œë”© ë¶€ë¶„ì€ Gradio UI í…ŒìŠ¤íŠ¸ ì¤‘ì—ëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
# í•„ìš”í•˜ë‹¤ë©´ ì„ì‹œë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ê³  í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# í•˜ì§€ë§Œ UI ì´ˆê¸°í™” ì˜¤ë¥˜ëŠ” ì´ ë¶€ë¶„ê³¼ ì§ì ‘ì ì¸ ê´€ë ¨ì´ ì—†ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
# print("ëª¨ë¸ ë¡œë”© ì‹œì‘...")
# repo_path = snapshot_download(repo_id=args.resume_path)
# pipeline = CatVTONPipeline(
#     base_ckpt=args.base_model_path,
#     attn_ckpt=repo_path,
#     attn_ckpt_version="mix",
#     weight_dtype=init_weight_dtype(args.mixed_precision),
#     use_tf32=args.allow_tf32,
#     device='cuda'
# )
# mask_processor = VaeImageProcessor(
#     vae_scale_factor=8,
#     do_normalize=False,
#     do_binarize=True,
#     do_convert_grayscale=True
# )
# automasker = AutoMasker(
#     densepose_ckpt=os.path.join(repo_path, "DensePose"),
#     schp_ckpt=os.path.join(repo_path, "SCHP"),
#     device='cuda',
# )
# print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

# ì‹¤ì œ submit_functionì€ ì¼ë‹¨ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤. (Minimal UIì—ì„œëŠ” í˜¸ì¶œë˜ì§€ ì•ŠìŒ)
@spaces.GPU(duration=120) # type: ignore
def submit_function(
    person_image_input, cloth_image_path, cloth_type,
    num_inference_steps, guidance_scale, seed, show_type
):
    # ... (ê¸°ì¡´ submit_function ë‚´ìš©) ...
    # ì´ í•¨ìˆ˜ëŠ” ì•„ë˜ minimal_app_gradioì—ì„œëŠ” ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    print("ì‹¤ì œ submit_function í˜¸ì¶œë¨ (ì´ ë©”ì‹œì§€ëŠ” minimal í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ë³´ì´ì§€ ì•Šì•„ì•¼ í•¨)")
    person_image_filepath = person_image_input["background"]
    mask_filepath = person_image_input["layers"][0] if person_image_input["layers"] else None

    if mask_filepath:
        mask = Image.open(mask_filepath).convert("L")
        if np.all(np.array(mask) == 0): mask = None
        else:
            mask_array = np.array(mask); mask_array[mask_array > 0] = 255; mask = Image.fromarray(mask_array)
    else: mask = None

    tmp_folder = args.output_dir
    date_str = datetime.now().strftime("%Y%m%d%H%M%S")
    result_save_path = os.path.join(tmp_folder, date_str[:8], date_str[8:] + ".png")
    if not os.path.exists(os.path.join(tmp_folder, date_str[:8])): os.makedirs(os.path.join(tmp_folder, date_str[:8]))

    generator = None
    if seed != -1: generator = torch.Generator(device='cuda').manual_seed(int(seed))

    person_image = Image.open(person_image_filepath).convert("RGB")
    cloth_image = Image.open(cloth_image_path).convert("RGB")
    person_image = resize_and_crop(person_image, (args.width, args.height))
    cloth_image = resize_and_padding(cloth_image, (args.width, args.height))

    if mask is not None: mask = resize_and_crop(mask, (args.width, args.height))
    else:
        print("ë§ˆìŠ¤í¬ê°€ ì œê³µë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì•„ AutoMaskerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        mask = automasker(person_image,cloth_type)['mask'] # type: ignore
    mask = mask_processor.blur(mask, blur_factor=9) # type: ignore

    # result_image = pipeline( # type: ignore
    #     image=person_image, condition_image=cloth_image, mask=mask,
    #     num_inference_steps=int(num_inference_steps), guidance_scale=float(guidance_scale), generator=generator
    # )[0]
    # ì„ì‹œë¡œ ë°˜í™˜ê°’ ì„¤ì • (pipeline í˜¸ì¶œ ì£¼ì„ ì²˜ë¦¬ ì‹œ)
    result_image = Image.new("RGB", (args.width, args.height), color="gray")


    masked_person = vis_mask(person_image, mask) # type: ignore
    save_result_image = image_grid([person_image, masked_person, cloth_image, result_image], 1, 4)
    save_result_image.save(result_save_path)

    if show_type == "result only": return result_image
    else:
        display_width, display_height = person_image.size
        if show_type == "input & result": condition_width = display_width // 2; conditions = image_grid([person_image, cloth_image], 2, 1)
        else: condition_width = display_width // 3; conditions = image_grid([person_image, masked_person, cloth_image], 3, 1)
        conditions = conditions.resize((condition_width, display_height), Image.Resampling.NEAREST)
        new_result_image = Image.new("RGB", (display_width + condition_width + 5, display_height))
        new_result_image.paste(conditions, (0, 0)); new_result_image.paste(result_image, (condition_width + 5, 0))
        return new_result_image

def person_example_fn(image_path_from_example):
    return image_path_from_example

# Custom CSS
css = """ footer {visibility: hidden} """ # CSS ê°„ì†Œí™” (í…ŒìŠ¤íŠ¸ ëª©ì )

# --- ë§¤ìš° ë‹¨ìˆœí™”ëœ app_gradio í•¨ìˆ˜ ---
def app_gradio():
    with gr.Blocks(theme=gr.themes.Soft(primary_hue="green", secondary_hue="blue"), css=css) as demo: # type: ignore
        gr.Markdown("# ğŸ‘” Fashion Fit (Minimal Test)")

        with gr.Row():
            with gr.Column():
                gr.Markdown("### Test Input")
                input_text = gr.Textbox(label="Test Input Textbox") # ì•„ì£¼ ê°„ë‹¨í•œ ì»´í¬ë„ŒíŠ¸
                test_button = gr.Button("Minimal Test Button") # type: ignore
            with gr.Column():
                gr.Markdown("### Test Output")
                output_text = gr.Textbox(label="Test Output Textbox")

        def minimal_test_func(text):
            print(f"Minimal test function called with: {text}")
            return f"Processed: {text}"

        test_button.click(
            minimal_test_func,
            inputs=[input_text],
            outputs=[output_text]
        )

    demo.queue().launch(share=True, show_error=True)
# --- ì—¬ê¸°ê¹Œì§€ ë§¤ìš° ë‹¨ìˆœí™”ëœ app_gradio í•¨ìˆ˜ ---

if __name__ == "__main__":
    # ëª¨ë¸ ë¡œë”©ì„ app_gradio í˜¸ì¶œ ì „ì— í• ì§€, í˜¹ì€ Gradio ë‚´ë¶€ì—ì„œ í• ì§€ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # UI ì´ˆê¸°í™” ì˜¤ë¥˜ ë””ë²„ê¹… ì¤‘ì´ë¯€ë¡œ, ì¼ë‹¨ì€ app_gradio()ë§Œ í˜¸ì¶œí•©ë‹ˆë‹¤.
    app_gradio()